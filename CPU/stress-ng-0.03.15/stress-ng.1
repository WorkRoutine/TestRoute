.\"                                      Hey, EMACS: -*- nroff -*-
.\" First parameter, NAME, should be all caps
.\" Second parameter, SECTION, should be 1-8, maybe w/ subsection
.\" other parameters are allowed: see man(7), man(1)
.TH STRESS-NG 1 "January 2, 2014"
.\" Please adjust this date whenever revising the manpage.
.\"
.\" Some roff macros, for reference:
.\" .nh        disable hyphenation
.\" .hy        enable hyphenation
.\" .ad l      left justify
.\" .ad b      justify to both left and right margins
.\" .nf        disable filling
.\" .fi        enable filling
.\" .br        insert line break
.\" .sp <n>    insert n+1 empty lines
.\" for manpage-specific macros, see man(7)
.\"
.\" left margin - right margin minus a fudge factor
.nr SZ ((\n[.l] - \n[.i]) / 1n - 31)
.nr SM ((\n[.l] - \n[.i]) / 1n - 41)
.nr SV ((\n[.l] - \n[.i]) / 1n - 30)
.SH NAME
stress\-ng \- a tool to load and stress a computer system
.br

.SH SYNOPSIS
.B stress\-ng
[\fIOPTION \fR[\fIARG\fR]] ...
.br

.SH DESCRIPTION
stress\-ng will stress test a computer system in various selectable ways. It
was designed to exercise various physical subsystems of a computer as well
as the various operating system kernel interfaces.
stress-ng also has a wide range of CPU specific stress tests that exercise floating point, integer, bit manipulation and control flow.
.PP
stress-ng was originally intended to make a machine work hard and trip
hardware issues such as thermal overruns as well as operating
system bugs that only occur when a system is being thrashed hard. Use stress-ng
with caution as some of the tests can make a system run hot
on poorly designed hardware and also can cause excessive system thrashing
which may be difficult to stop.
.PP
stress-ng can also measure test throughput rates; this can be
useful to observe performance changes across different
operating system releases or types of hardware. However, it has never been
intended to be used as a precise benchmark test suite, so do NOT use it
in this manner.
.PP
Running stress-ng with root privileges will adjust out of memory settings
on Linux systems to make the stressors unkillable in low memory situations,
so use this judiciously.  With the appropriate privilege, stress-ng can allow
the ionice class and ionice levels to be adjusted, again, this should be
used with care.
.PP
One can specify the number of processes to invoke per type of stress test; specifying
a negative or zero value will select the number of online processors as defined
by sysconf(_SC_NPROCESSORS_ONLN).
.SH OPTIONS
.TP
.B \-\-affinity N
start N processes that rapidly change CPU affinity (only on Linux). Rapidly switching
CPU affinity can contribute to poor cache behaviour.
.TP
.B \-\-affinity\-ops N
stop affinity processes after N bogo affinity operations (only on Linux).
.TP
.B \-\-affinity\-rand
switch CPU affinity randomly rather than the default of sequentially.
.TP
.B \-\-aio N
start N processes that issue multiple small asynchronous I/O writes and reads on a relatively small
temporary file.  This will just hit the file system cache and soak up a lot of user and kernel time
in issuing and handling I/O requests.  By default, each process will handle 16 concurrent I/O requests.
.TP
.B \-\-aio\-ops N
stop asynchronous I/O workers after N bogo asynchronous I/O requests.
.TP
.B \-\-aio\-requests N
specify the number of asynchronous I/O requests each process should issue, the default is 16; 1 to 4096 are allowed.
.TP
.B \-a N, \-\-all N
start N instances of each stress test.
.TP
.B \-b N, \-\-backoff N
wait N microseconds between the start of each stress process. This allows one
to ramp up the stress tests over time.
.TP
.B \-B N, \-\-bigheap N
start N processes that grow their heaps by reallocating memory. If the out of memory
killer (OOM) on Linux kills the process or the allocation fails then the allocating process starts all
over again.  Note that the OOM adjustment for the process is set so that the OOM killer
will treat these processes as the first candidate processes to kill.
.TP
.B \-\-bigheap\-ops N
stop the big heap processes after N bogo allocation operations are completed.
.TP
.B \-\-bigheap\-growth N
specify amount of memory to grow heap by per iteration. Size can be from 4K to 64MB. Default is 64K.
.TP
.B \-\-brk N
start N processes that grow the data segment by one page at a time using multiple brk(2) calls. Each successfully allocated new page is touched to ensure it is resident in memory.  If an out of memory condition occurs then the test will reset the data segment to the point before it started and repeat the data segment resizing over again.  The process adjusts the out of memory setting so that it may be killed by the out of memory (OOM) killer before other processes. If it is killed by the OOM killer then it will be automatically re-started by a monitoring parent process.
.TP
.B \-\-brk\-ops N
stop the brk stressor after N bogo brk operations.
.TP
.B \-\-brk\-notouch
do not touch each newly allocated data segment page. This disables the default of touching each newly allocated page and hence avoids the kernel from necessarily backing the page with real physical memory.
.TP
.B \-\-bsearch N
start N processes that binary search a sorted array of 32 bit integers using bsearch(3). By default, there are 65536 elements in the array.  This is a useful method to exercise random access of memory and processor cache.
.TP
.B \-\-bsearch\-ops N
stop the bsearch processes after N bogo bsearch operations are completed.
.TP
.B \-\-bsearch\-size N
specify the size (number of 32 bit integers) in the array to bsearch. Size can be from 1K to 4M.
.TP
.B \-C N, \-\-cache N
start N processes that perform random wide spread memory read and writes to thrash the CPU cache.  The code does not intelligently determine the CPU cache configuration and so it may be sub-optimal in producing hit-miss read/write activity for some processors.
.TP
.B \-\-cache\-fence
force write serialization on each store operation (x86 only). This is a no-op for non-x86 architectures.
.TP
.B \-\-cache\-flush
force flush cache on each store operation (x86 only). This is a no-op for non-x86 architectures.
.TP
.B \-\-cache\-ops N
stop cache thrash processes after N bogo cache thrash operations.
.TP
.B \-\-chmod N
start N processes that change the file mode bits via chmod(2) and fchmod(2) on the same file. The greater the value for N then the more contention on the single file.  The stressor will work through all the combination of mode bits.
.TP
.B \-\-chmod\-ops N
stop after N chmod bogo operations.
.TP
.B \-\-class name
specify the class of stressors to run. Stressors are classified into one or more of the following classes: cpu, cpu-cache, io, interrupt, memory, network, os, scheduler and vm.  Some stressors fall into just one class. For example the 'get' stressor is just in the 'os' class. Other stressors fall into more than one class, for example, the 'lsearch' stressor falls into the 'cpu', 'cpu-cache' and 'memory' classes as it exercises all these three.  Selecting a specific class will run all the stressors that fall into that class only when run with the \-\-sequential option.
.TP
.B \-\-clock N
start N processes exercising clocks and POSIX timers. For all known clock types this will exercise clock_getres(2), clock_gettime(2) and clock_nanosleep(2). For
all known timers it will create a 50000ns timer and busy poll this until it expires.  This stressor will cause frequent context switching.
.TP
.B \-\-clock\-ops N
stop clock stress processes after N bogo operations.
.TP
.B \-c N, \-\-cpu N
start N processes exercising the CPU by sequentially working through all the different CPU stress methods. Instead of exercising all the CPU stress methods, one can specify a specific CPU stress method with the \-\-cpu\-method option.
.TP
.B \-\-cpu\-ops N
stop cpu stress processes after N bogo operations.
.TP
.B \-l P, \-\-cpu\-load P
load CPU with P percent loading. 0 is effectively a sleep (no load) and 100 is full loading.  The loading loop is broken into compute time (load%) and sleep time (100% - load%). Accuracy depends on the overall load of the processor and the responsiveness of the scheduler, so the actual load may be different from the desired load.  Note that the number of bogo CPU operations may not be linearly scaled with the load as some systems employ CPU frequency scaling and so heavier loads produce an increased CPU frequency and greater CPU bogo operations.
.TP
.B \-\-cpu\-method method
specify a cpu stress method. By default, all the stress methods are exercised sequentially, however one can specify just one method to be used if required. Available cpu stress methods are described as follows:
.TS
expand;
lB2 lBw(\n[SZ]n)
l l.
Method	Description
all	T{
iterate over all the below cpu stress methods
T}
ackermann	T{
Ackermann function: compute A(3, 10), where:
 A(m, n) = n + 1 if m = 0;
 A(m - 1, 1) if m > 0 and n = 0;
 A(m - 1, A(m, n - 1)) if m > 0 and n > 0
T}
bitops	T{
various bit operations from bithack, namely: reverse bits, parity check, bit count, round to nearest power of 2
T}
cfloat	T{
1000 iterations of a mix of floating point complex operations
T}
cdouble	T{
1000 iterations of a mix of double floating point complex operations
T}
clongdouble	T{
1000 iterations of a mix of long double floating point complex operations
T}
correlate	T{
perform a 16384 \(mu 1024 correlation of random doubles
T}
crc	T{
compute 1024 rounds of CCITT CRC16 on random data
T}
decimal32	T{
1000 iterations of a mix of 32 bit decimal floating point operations (GCC only)
T}
decimal64	T{
1000 iterations of a mix of 64 bit decimal floating point operations (GCC only)
T}
decimal128	T{
1000 iterations of a mix of 128 bit decimal floating point operations (GCC only)
T}
djb2a	T{
128 rounds of hash DJB2a (Dan Bernstein hash using the xor variant) on 128 to 1 bytes of random strings
T}
double	T{
1000 iterations of a mix of double precision floating point operations
T}
euler	T{
compute e using n \[eq] (1 + (1 \[di] n)) \[ua] n
T}
explog	T{
iterate on n \[eq] exp(log(n) \[di] 1.00002)
T}
fibonacci	T{
compute Fibonacci sequence of 0, 1, 1, 2, 5, 8...
T}
fft	T{
4096 sample Fast Fourier Transform
T}
float	T{
1000 iterations of a mix of floating point operations
T}
fnv1a	T{
128 rounds of hash FNV-1a (Fowler–Noll–Vo hash using the xor then multiply variant) on 128 to 1 bytes of random strings
T}
gamma	T{
calculate the Euler\-Mascheroni constant \(*g using the limiting difference between the harmonic series (1 + 1/2 + 1/3 + 1/4 + 1/5 ... + 1/n) and the natural logarithm ln(n), for n = 80000.
T}
gcd	T{
compute GCD of integers
T}
gray	T{
calculate binary to gray code and gray code back to binary for integers
from 0 to 65535
T}
hamming	T{
compute Hamming H(8,4) codes on 262144 lots of 4 bit data. This turns 4 bit data into 8 bit Hamming code containing 4 parity bits. For data bits d1..d4, parity bits are computed as:
  p1 = d2 + d3 + d4
  p2 = d1 + d3 + d4
  p3 = d1 + d2 + d4
  p4 = d1 + d2 + d3
T}
hanoi	T{
solve a 21 disc Towers of Hanoi stack using the recursive solution
T}
hyperbolic	T{
compute sinh(\(*h) \(mu cosh(\(*h) + sinh(2\(*h) + cosh(3\(*h) for float, double and long double hyperbolic sine and cosine functions where \(*h = 0 to 2\(*p in 1500 steps
T}
idct	T{
8 \(mu 8 IDCT (Inverse Discrete Cosine Transform)
T}
int8	T{
1000 iterations of a mix of 8 bit integer operations
T}
int16	T{
1000 iterations of a mix of 16 bit integer operations
T}
int32	T{
1000 iterations of a mix of 32 bit integer operations
T}
int64	T{
1000 iterations of a mix of 64 bit integer operations
T}
int128	T{
1000 iterations of a mix of 128 bit integer operations (GCC only)
T}
int32float	T{
1000 iterations of a mix of 32 bit integer and floating point operations
T}
int32double	T{
1000 iterations of a mix of 32 bit integer and double precision floating point operations
T}
int32longdouble	T{
1000 iterations of a mix of 32 bit integer and long double precision floating point operations
T}
int64float	T{
1000 iterations of a mix of 64 bit integer and floating point operations
T}
int64double	T{
1000 iterations of a mix of 64 bit integer and double precision floating point operations
T}
int64longdouble	T{
1000 iterations of a mix of 64 bit integer and long double precision floating point operations
T}
int128float	T{
1000 iterations of a mix of 128 bit integer and floating point operations (GCC only)
T}
int128double	T{
1000 iterations of a mix of 128 bit integer and double precision floating point operations (GCC only)
T}
int128longdouble	T{
1000 iterations of a mix of 128 bit integer and long double precision floating point operations (GCC only)
T}
int128decimal32	T{
1000 iterations of a mix of 128 bit integer and 32 bit decimal floating point operations (GCC only)
T}
int128decimal64	T{
1000 iterations of a mix of 128 bit integer and 64 bit decimal floating point operations (GCC only)
T}
int128decimal128	T{
1000 iterations of a mix of 128 bit integer and 128 bit decimal floating point operations (GCC only)
T}
jenkin	T{
Jenkin's integer hash on 128 rounds of 128..1 bytes of random data
T}
jmp	T{
Simple unoptimised compare >, <, == and jmp branching
T}
ln2	T{
compute ln(2) based on series:
 1 - 1/2 + 1/3 - 1/4 + 1/5 - 1/6 ...
T}
longdouble	T{
1000 iterations of a mix of long double precision floating point operations
T}
loop	T{
simple empty loop
T}
matrixprod	T{
matrix product of two 128 \(mu 128 matrices of double floats. Testing on 64 bit x86 hardware shows that this is provides a good mix of memory, cache and floating point operations and is probably the best CPU method to use to make a CPU run hot.
T}
nsqrt	T{
compute sqrt() of long doubles using Newton-Raphson
T}
omega	T{
compute the omega constant defined by \(*We\[ua]\(*W = 1 using efficient iteration of \(*Wn+1 = (1 + \(*Wn) / (1 + e\[ua]\(*Wn)
T}
phi	T{
compute the Golden Ratio \(*f using series
T}
pi	T{
compute \(*p using the Srinivasa Ramanujan fast convergence algorithm
T}
pjw	T{
128 rounds of hash pjw function on 128 to 1 bytes of random strings
T}
prime	T{
find all the primes in the range  1..1000000 using a slightly
optimised brute force na\[:i]ve trial division search
T}
psi	T{
compute \(*q (the reciprocal Fibonacci constant) using the sum of the
reciprocals of the Fibonacci numbers
T}
rand	T{
16384 iterations of rand(), where rand is the MWC pseudo
random number generator.
The MWC random function concatenates two 16 bit multiply\-with\-carry generators:
 x(n) = 36969 \(mu x(n - 1) + carry,
 y(n) = 18000 \(mu y(n - 1) + carry mod 2 \[ua] 16
.br
and has period of around 2 \[ua] 60
T}
rgb	T{
convert RGB to YUV and back to RGB (CCIR 601)
T}
sdbm	T{
128 rounds of hash sdbm (as used in the SDBM database and GNU awk) on 128 to 1 bytes of random strings
T}
sieve	T{
find the primes in the range 1..10000000 using the sieve of Eratosthenes
T}
sqrt	T{
compute sqrt(rand()), where rand is the MWC pseudo random number generator
T}
trig	T{
compute sin(\(*h) \(mu cos(\(*h) + sin(2\(*h) + cos(3\(*h) for float, double and long double sine and cosine functions where \(*h = 0 to 2\(*p in 1500 steps
T}
zeta	T{
compute the Riemann Zeta function \[*z](s) for s = 2.0..10.0
T}
.TE
.RS
.PP
Note that some of these methods try to exercise the CPU with
computations found in some real world use cases. However, the
code has not been optimised on a per-architecture basis, so
may be a sub-optimal compared to hand-optimised code used
in some applications.  They do try to represent
the typical instruction mixes found in these use cases.
.RE
.TP
.B \-D N, \-\-dentry N
start N processes that create and remove directory entries.  This should create file system meta data activity. The
directory entry names are suffixed by a gray-code encoded number to try to mix up the hashing of the namespace.
.TP
.B \-\-dentry\-ops N
stop denty thrash processes after N bogo dentry operations.
.TP
.B \-\-dentry\-order O
specify unlink order of dentries, can be one of forward, reverse or stride. By default, dentries are unlinked
in the order they were created, however, the reverse order option will unlink them from last to first and the
stride option will unlink them by stepping around order in a quasi-random pattern.
.TP
.B \-\-dentries N
create N dentries per dentry thrashing loop, default is 2048.
.TP
.B \-\-dir N
start N processes that create and remove directories using mkdir and rmdir.
.TP
.B \-\-dir\-ops N
stop directory thrash processes after N bogo directory operations.
.TP
.B \-n, \-\-dry\-run
parse options, but don't run stress tests. A no-op.
.TP
.B \-\-dup N
start N processes that perform dup(2) and then close(2) operations on /dev/zero. The maximum opens at one time is system defined, so the test will run up to this maximum, or 65536 open file descriptors, which ever comes first.
.TP
.B \-\-dup\-ops N
stop the dup stress processes after N bogo open operations.
.TP
.B \-\-epoll N
start N stressors that perform various related socket stress activity using epoll_wait to monitor and handle new connections. This involves client/server processes performing rapid connect, send/receives and disconnects on the local host.  Using epoll allows a large number of connections to be efficiently handled, however, this can lead to the connection table filling up and blocking further socket connections, hence impacting on the epoll bogo op stats.  For ipv4 and ipv6
domains, multiple servers are spawned on multiple ports. The epoll stressor is for Linux only.
.TP
.B \-\-epoll\-domain D
specifty the domain to use, the default is unix (aka local). Currently ipv4, ipv6 and unix are supported.
.TP
.B \-\-epoll\-port P
start at socket port P. For N epoll worker processes, ports P to (P * 4) - 1 are used for ipv4, ipv6 domains and ports P to P - 1 are used for the unix domain.
.TP
.B \-\-epoll\-ops N
stop epoll stress processes after N bogo operations.
.TP
.B \-\-eventfd N
start N parent and child worker processes that read and write 8 byte event messages between them via the eventfd mechanism (Linux only).
.TP
.B \-\-eventfd\-ops N
stop eventfd workers after N bogo operations.
.TP
.B \-F N, \-\-fallocate N
start N processes continually fallocating (preallocating file space) and ftuncating (file truncating) temporary files.
.TP
.B \-\-fallocate\-ops N
stop fallocate stress processes after N bogo fallocate operations.
.TP
.B \-\-fault N
start N processes that generates minor and major page faults.
.TP
.B \-\-fault\-ops N
stop the page fault processes after N bogo page fault operations.
.TP
.B \-\-fifo N
start N workers that exercise a named pipe transmitting 64 bit integers.
.TP
.B \-\-fifo-ops N
stop fifo workers after N bogo pipe write operations.
.TP
.B \-\-fifo-readers N
for each worker, create N fifo reader processes that read
the named pipe using simple blocking reads.
.TP
.B \-\-flock N
start N processes locking on a single file.
.TP
.B \-\-flock\-ops N
stop flock stress processes after N bogo flock operations.
.TP
.B \-f N, \-\-fork N
start N processes continually forking children that immediately exit.
.TP
.B \-\-fork\-ops N
stop fork stress processes after N bogo operations.
.TP
.B \-\-fork\-max P
create P processes and then wait for them to exit per iteration. The default is just 1; higher
values will create many temporary zombie processes that are waiting to be reaped. One can
potentially fill up the the process table using high values for \-\-fork\-max and \-\-fork.
.TP
.B \-\-fstat N
start N processes fstat'ing files in a directory (default is /dev).
.TP
.B \-\-fstat\-ops N
stop fstat stress process after N bogo fstat operations.
.TP
.B \-\-fstat\-dir directory
specify the directory to fstat to override the default of /dev.
All the files in the directory will be fstat'd repeatedly.
.TP
.B \-\-futex N
start N stressors that rapidly exercise the futex system call. Each stressor has two processes, a futex waiter and a futex waker. The waiter waits with a very small timeout to stress the timeout and rapid polled futex waiting. This is a Linux specific stress option.
.TP
.B \-\-futex\-ops N
stop futex stressors after N bogo successful futex wait operations.
.TP
.B \-\-get N
start N stressors that call all the get*(2) system calls.
.TP
.B \-\-get\-ops N
stop get stressors after N bogo get operations.
.TP
.B \-d N, \-\-hdd N
start N processes continually writing and removing temporary files.
.TP
.B \-\-hdd\-bytes N
write N bytes for each hdd process, the default is 1 GB. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-hdd\-opts list
specify various stress test options as a comma separated list. Options are as follows:
.TS
expand;
lB lBw(\n[SZ]n)
l l.
Option	Description
direct	T{
try to minimize cache effects of the I/O. File I/O writes are performed directly from user space buffers and synchronous transfer is also attempted. To guarantee synchronous I/O, also use the sync option.
T}
dsync	T{
ensure output has been transferred to underlying hardware and file metadata has been updated. This is equivalent to each write(2) being followed by a call to fdatasync(2).
T}
noatime	T{
do not update the file last access timestamp, this can reduce metadata writes.
T}
sync	T{
ensure output has been transferred to underlying hardware. This is equivalent to a each write(2) being followed by a call to fdatasync(2).
T}
wr\-seq	T{
write data sequentially. This is the default if no write modes are specified.
T}
wr\-rnd	T{
write data randomly. The wr\-seq option cannot be used at the same time.
T}
rd\-seq	T{
read data sequentially. By default, written data is not read back, however, this option will force it to be read back sequentially.
T}
rd\-rnd	T{
read data randomly. By default, written data is not read back, however, this option will force it to be read back randonly.
T}
fadv\-normal	T{
advise kernel there are no explicit access pattern for the data. This is the default advice assumption.
T}
fadv\-seq	T{
advise kernel to expect sequential access patterns for the data.
T}
fadv\-rnd	T{
advise kernel to expect random access patterns for the data.
T}
fadv\-noreuse	T{
advise kernel to expect the data to be accessed only once.
T}
fadv\-willneed	T{
advise kernel to expect the data to be accessed in the near future.
T}
fadv\-dontneed	T{
advise kernel to expect the data will not be accessed in the near future.
T}
.TE
.br

Note that some of these options are mutually exclusive, for example, there can be only one method of writing or reading.  Also, fadvise flags may be mutually exclusive, for example fadv-willneed cannot be used with fadv-dontneed.
.TP
.B \-\-hdd\-ops N
stop hdd stress processes after N bogo operations.
.TP
.B \-\-hdd\-sync
.B \-\-hdd\-write\-size N
specify size of each write in bytes. Size can be from 1 byte to 4MB.
.TP
.B \-h, \-\-help
show help.
.TP
.B \-\-hsearch N
start N processes that search a 80% full hash table using hsearch(3). By default, there are 8192 elements inserted  into the hash table.  This is a useful method to exercise access of memory and processor cache.
.TP
.B \-\-hsearch\-ops N
stop the hsearch processes after N bogo hsearch operations are completed.
.TP
.B \-\-hsearch\-size N
specify the number of hash entries to be inserted into the hash table. Size can be from 1K to 4M.
.TP
.B \-\-inotify N
start N processes performing file system activities such as making/deleting files/directories, moving files, etc. to stress exercise the various inotify events (Linux only).
.TP
.B \-\-inotify\-ops N
stop inotify stress processes after N inotify bogo operations.
.TP
.B \-i N, \-\-io N
start N processes continuously calling sync(2) to commit buffer cache to disk. This can be used in conjunction with the \-\-hdd options.
.TP
.B \-\-io\-ops N
stop io stress processes after N bogo operations.
.TP
.B \-\-ionice\-class class
specify ionice class (only on Linux). Can be idle (default), besteffort, be, realtime, rt.
.TP
.B \-\-ionice\-level level
specify ionice level (only on Linux). For idle, 0 is the only possible option. For besteffort or realtime values 0 (hightest priority) to 7 (lowest priority). See ionice(1) for more details.
.TP
.B \-k, \-\-keep\-name
by default, stress-ng will attempt to change the name of the stress processes according to their functionality; this option disables this and keeps the process names to be the name of the parent process, that is, stress-ng.
.TP
.B \-\-kill N
start N processes sending SIGUSR1 kill signals to a SIG_IGN signal handler. Most of the process time will end up in kernel space.
.TP
.B \-\-kill\-ops N
stop kill processes after N bogo kill operations.
.TP
.B \-\-lease N
start N processes locking, unlocking and breaking leases via the fcntl(2) F_SETLEASE operation. The parent processes continually lock and unlock a lease on a file while a user selectable number of child processes open the file with a non-blocking open to generate SIGIO lease breaking notifications to the parent.  This stressor is only available if F_SETLEASE, F_WRLCK and F_UNLCK support is provided by fcntl(2).
.TP
.B \-\-lease\-ops N
stop lease stressors after N bogo operations.
.TP
.B \-\-lease\-breakers N
start N lease breaker child processes per lease stressor.  Normally one child is plenty to force many SIGIO lease breaking notification signals to the parent, however, this option allows one to specify more child processes if required.
.TP
.B \-\-link N
start N processes creating and removing hardlinks.
.TP
.B \-\-link\-ops N
stop link stress processes after N bogo operations.
.TP
.B \-\-lockf N
start N processes randomly locking regions of a file using the POSIX lockf(3) locking mechanism. A single 4K file is locked in one of two randonly chosen 2K regions at offsets 0 and 2K.
.TP
.B \-\-lockf\-ops N
stop lockf stress processes after N bogo lockf operations.
.TP
.B \-\-lockf\-nonblock
instead of using blocking F_LOCK lockf(3) commands, use non-blocking F_TLOCK commands and re-try if the lock failed.  This creates extra system call overhead and CPU utilisation as the number of lockf stressors increases and hence increases locking contention.
.TP
.B \-\-lsearch N
start N processes that linear search a unsorted array of 32 bit integers using lsearch(3). By default, there are 8192 elements in the array.  This is a useful method to exercise sequential access of memory and processor cache.
.TP
.B \-\-lsearch\-ops N
stop the lsearch processes after N bogo lsearch operations are completed.
.TP
.B \-\-malloc N
start N processes continuously calling malloc(3), calloc(3), realloc(3) and free(3). By default, up to 65536 allocations can be active at any point, but this can be altered with the \-\-malloc\-max option.  Allocation, reallocation and freeing are chosen at random; 50% of the time memory is allocation (via malloc, calloc or realloc) and 50% of the time allocations are free'd.  Allocation sizes are also random, with the maximum allocation size controlled by the \-\-malloc\-bytes option, the default size being 64K.  The stressor is re-started if it is killed by the out of mememory (OOM) killer.
.TP
.B \-\-malloc\-bytes N
maximum per allocation/reallocation size. Allocations are randomly selected from from 1 to N bytes. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.  Large allocation sizes cause the memory allocator to use mmap(2) rather than expanding the heap using brk(2).
.TP
.B \-\-malloc\-max N
maximum number of active allocations allowed. Allocations are chosen at ramdom and placed in an allocation slot. Because about 50%/50% split between allocation and freeing, typically half of the allocation slots are in use at any one time.
.TP
.B \-\-malloc\-ops N
stop after N malloc bogo operations. One bogo operations relates to a successfull malloc(3), calloc(3) or realloc(3).
.TP
.B \-\-lsearch\-size N
specify the size (number of 32 bit integers) in the array to lsearch. Size can be from 1K to 4M.
.TP
.B \-\-metrics
output number of bogo operations in total performed by the stress processes. Note that these are not a reliable metric of performance or throughput and have not
been designed to be used for benchmarking whatsoever. The metrics are just a useful way to observe how a system behaves when under various kinds of load.
.RS
.PP
The following columns of information are output:
.TS
expand;
lB lBw(\n[SM]n)
l l.
Column Heading	Explanation
T{
bogo ops
T}	T{
number of iterations of the stressor during the run. This is metric of
how much overall "work" has been achieved in bogo operations.
T}
T{
real time (secs)
T}	T{
average wall clock duration (in seconds) of the stressor. This is the total wall clock time of all the instances of that particular stressor divided by the number of these stressors being run.
T}
T{
usr time (secs)
T}	T{
total user time (in seconds) consumed running all the instances of the stressor.
T}
T{
sys time (secs)
T}	T{
total system time (in seconds) consumed running all the instances of the stressor.
T}
T{
bogo ops/s (real time)
T}	T{
total bogo operations per second based on wall clock run time. The wall clock time reflects
the apparent run time. The more processors one has on a system the more the work load can be
distributed onto these and hence the wall clock time will reduce and the bogo ops rate will
increase.  This is essentially the "apparent" bogo ops rate of the system.
T}
T{
bogo ops/s (usr+sys time)
T}	T{
total bogo operations per second based on cumulative user and system time. This is the real
bogo ops rate of the system taking into consideration the actual time execution time of
the stressor across all the processors.  Generally this will decrease as one adds more
concurrent stressors due to contention on cache, memory, execution units, buses and I/O devices.
T}
.TE
.RE
.TP
.B -\-metrics\-brief
enable metrics and only output metrics that are non-zero.
.TP
.B \-\-memcpy N
start N processes that copy 2MB of data from a shared region to a buffer using memcpy(3) and then move the data in the buffer with memmove(3) with 3 different alignments. This will exercise processor cache and system memory.
.TP
.B \-\-memcpy\-ops N
stop memcpy stress processes after N bogo memcpy operations.
.TP
.B \-\-mincore N
start N processes that walk through all of memory 1 page at a time checking of the page mapped and also is resident in memory using mincore(2).
.TP
.B \-\-mincore\-ops N
stop after N mincore bogo operations. One mincore bogo op is equivalent to a 1000 mincore(2) calls.
.TP
.B \-\-mincore\-random
instead of walking through pages sequentially, select pages at random. The chosen address is iterated over by shifting it right one place and checked by mincore until the address is less or equal to the page size.
.TP
.B \-\-mmap N
start N processes continuously calling mmap(2)/munmap(2).  The initial mapping is a large chunk (size specified by \-\-mmap\-bytes) followed by pseudo-random 4K unmappings, then pseudo-random 4K mappings, and then linear 4K unmappings. Note that this can cause systems to trip the kernel OOM killer on Linux systems if not enough physical memory and swap is not available.  The MAP_POPULATE option is used to populate pages into memory on systems that support this.  By default, anonymous mappings are used, however, the \-\-mmap\-file and \-\-mmap\-async options allow one to perform file based mappings if desired.
.TP
.B \-\-mmap\-ops N
stop mmap stress processes after N bogo operations.
.TP
.B \-\-mmap\-async
enable file based memory mapping and use asynchronous msync'ing on each page, see \-\-mmap\-file.
.TP
.B \-\-mmap\-bytes N
allocate N bytes per mmap stress process, the default is 256MB. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-mmap\-file
enable file based memory mapping and by default use synchronous msync'ing on each page.
.TP
.B \-\-mmap\-mprotect
change protection settings on each page of memory.  Each time a page or a group of pages are mapped or remapped then this option will make the pages read-only, write-only, exec-only, and read-write.
.TP
.B \-\-mremap N
start N processes continuously calling mmap(2), mremap(2) and munmap(2).  The initial anonymous mapping is a large chunk (size specified by \-\-mremap\-bytes) and then iteratively halved in size by remapping all the way down to a page size and then back up to the original size.  This stressor is only available for Linux.
.TP
.B \-\-mremap\-ops N
stop mremap stress processes after N bogo operations.
.TP
.B \-\-mremap\-bytes N
initially allocate N bytes per remmap stress process, the default is 256MB. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-msg N
start N sender and receiver processes that continually send and receive messages using System V message IPC.
.TP
.B \-\-msg\-ops N
stop after N bogo message send operations completed.
.TP
.B \-\-mq N
start N sender and receiver processes that continually send and receive messages using POSIX message queues. (Linux only).
.TP
.B \-\-mq\-ops N
stop after N bogo POSIX message send operations completed.
.TP
.B \-\-mq\-size N
specify size of POSIX message queue. The default size is 10 messages and most Linux systems this is the maximum allowed size for normal users. If the given size is greater than the allowed message queue size then a warning is issued and the maximum allowed size is used instead.
.TP
.B \-\-nice N
start N cpu consuming processes that exercise the available nice levels. Each iteration forks off a child process that runs through the all the nice levels running a busy loop for 0.1 seconds per level and then exits.
.TP
.B \-\-nice\-ops N
stop after N nice bogo nice loops
.TP
.B \-\-no\-advise
from version 0.02.26 stress-ng automatically calls madvise(2) with random advise options before each mmap and munmap to stress the the vm subsystem a little harder. The \-\-no\-advise option turns this default off.
.TP
.B \-\-null N
start N processes writing to /dev/null.
.TP
.B \-\-null\-ops N
stop null stress processes after N /dev/null bogo write operations.
.TP
.B \-o N, \-\-open N
start N processes that perform open(2) and then close(2) operations on /dev/zero. The maximum opens at one time is system defined, so the test will run up to this maximum, or 65536 open file descriptors, which ever comes first.
.TP
.B \-\-open\-ops N
stop the open stress processes after N bogo open operations.
.TP
.B \-\-page\-in
touch allocated pages that are not in core, forcing them to be paged back in.  This is a useful option to force
all the allocated pages to be paged in when using the bigheap, mmap and vm stressors.  It will severely degrade
performance when the memory in the system is less than the allocated buffer sizes.  This uses mincore(2) to determine the pages that are not in core and hence need touching to page them back in.
.TP
.B \-p N, \-\-pipe N
start N stressors that perform large pipe writes and reads to exercise pipe I/O. This exercises memory write and reads as well as context switching.  Each stressor has two processes, a reader and a writer.
.TP
.B \-\-pipe\-ops N
stop pipe stress processes after N bogo pipe write operations.
.TP
.B \-P N, \-\-poll N
start N processes that perform zero timeout polling via the poll(2), select(2) and sleep(3) calls. This wastes system and user time doing nothing.
.TP
.B \-\-poll\-ops N
stop poll stress processes after N bogo poll operations.
.TP
.B \-\-procfs N
start N processes that read files from /proc and recursively read files from /proc/self (Linux only).
.TP
.B \-\-procfs\-ops N
stop procfs reading after N bogo read operations. Note, since the number of entries may vary between kernels, this bogo ops metric is probably very misleading.
.TP
.B \-\-pthread N
start N workers that iteratively creates and terminates multiple pthreads (the default is 16 pthreads 16 worker). In each iteration, each newly created pthread waits until the worker has created all the pthreads and then they all terminate together.
.TP
.B \-\-pthread\-ops N
stop pthread workers after N bogo pthread create operations.
.TP
.B \-\-pthread\-max N
create N pthreads per worker. If the product of the number of pthreads by the number of workers is greater than the soft limit of allowed pthreads then the maximum is re-adjusted down to the maximum allowed.
.TP
.B \-Q, \-\-qsort N
start N processes that sort 32 bit integers using qsort.
.TP
.B \-\-qsort\-ops N
stop qsort stress processes after N bogo qsorts.
.TP
.B \-\-qsort\-size N
specify number of 32 bit integers to sort, default is 262144 (256 \(mu 1024).
.TP
.B \-q, \-\-quiet
do not show any output.
.TP
.B \-r N, \-\-random N
start N random stress processes.
.TP
.B \-\-rdrand N
start N processes that read the Intel hardware random number generator (Intel Ivybridge processors upwards).
.TP
.B \-\-rdrand\-ops N
stop rdrand stress processes after N bogo rdrand operations (1 bogo op = 2048 random bits successfully read).
.TP
.B \-R N, \-\-rename N
start N processes that each create a file and then repeatedly rename it.
.TP
.B \-\-rename\-ops N
stop rename stress processes after N bogo rename operations.
.TP
.B \-\-sched scheduler
select the named scheduler (only on Linux). To see the list of available schedulers
use: stress\-ng \-\-sched which
.TP
.B \-\-sched\-prio prio
select the scheduler priority level (only on Linux). If the scheduler does not support this then
the default priority level of 0 is chosen.
.TP
.B \-\-seek N
start N processes that randomly seeks and performs 512 byte read/write I/O operations on a file. The default file size is 16 GB.
.TP
.B \-\-seek\-ops N
stop seek stress processes after N bogo seek operations.
.TP
.B \-\-seek\-size N
specify the size of the file in bytes. Small file sizes allow the I/O to occur in the cache, causing greater CPU load. Large file sizes force
more I/O operations to drive causing more wait time and more I/O on the drive. One can specify the size in units of Bytes, KBytes, MBytes and
GBytes using the suffix b, k, m or g.
.TP
.B \-\-sem N
start N workers that perform POSIX semaphore wait and post operations. By default, a parent and 4 children are started per worker to provide some contention on the semaphore. This stresses fast semaphore operations and produces rapid context switching.
.TP
.B \-\-sem\-ops N
stop semaphore stress processes after N bogo semaphore operations.
.TP
.B \-\-sem\-procs N
start N child processes per worker to provide contention on the semaphore, the default is 4 and a maximum of 64 are allowed.
.TP
.B \-\-sem\-sysv N
start N workers that perform System V semaphore wait and post operations. By default, a parent and 4 children are started per worker to provide some contention on the semaphore. This stresses fast semaphore operations and produces rapid context switching.
.TP
.B \-\-sem\-sysv\-ops N
stop semaphore stress processes after N bogo System V semaphore operations.
.TP
.B \-\-sem\-sysv\-procs N
start N child processes per worker to provide contention on the System V semaphore, the default is 4 and a maximum of 64 are allowed.
.TP
.B \-\-sendfile N
start N processes that send an empty file to /dev/null. This operation spends nearly all the time in the kernel.  The default sendfile size is 4MB.  The sendfile options are for Linux only.
.TP
.B \-\-sendfile\-ops N
stop sendfile stressors after N sendfile bogo operations.
.TP
.B \-\-sendfile\-size S
specify the size to be copied with each sendfile call. The default size is 4MB. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-sequential N
sequentially run all the stressors one by one for a default of 60 seconds. The
number of each individual stressors to be started is N.  If N is zero, then a
stressor for each processor that is on-line is executed. Use the \-\-timeout
option to specify the duration to run each stressor.
.TP
.B \-\-shm\-sysv N
start N processes that allocate shared memory using the System V shared memory interface.  By default, the test will repeatedly create and destroy 8 shared memory segments, each of which is 8MB in size.
.TP
.B \-\-shm\-sysv\-ops N
stop after N shared memory create and destroy bogo operations are complete.
.TP
.B \-\-shm\-sysv\-bytes N
specify the size of the shared memory segment to be created. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-shm\-sysv\-segs N
specify the number of shared memory segments to be created.
.TP
.B \-\-sigfd N
start N processess that generate SIGUSR1 signals and are handled by reads by a child process using a file descriptor set up using signalfd(2).  (Linux only). This will generate a heavy context switch load.
.TP
.B \-\-sigfd\-ops
stop sigfd processes after N bogo SIGUSR1 signals are sent.
.TP
.B \-\-sigfpe N
start N processes that rapidly cause division by zero SIGFPE faults.
.TP
.B \-\-sigfpe\-ops N
stop sigfpe stress processes after N bogo SIGFPE faults.
.TP
.B \-\-sigsegv N
start N processes that rapidly create and catch segmentation faults.
.TP
.B \-\-sigsegv\-ops N
stop sigsegv stress processes after N bogo segmentation faults.
.TP
.B \-\-sigq N
start N processes that rapidly send SIGUSR1 signals using sigqueue(3) to child processes that wait for the signal via sigwaitinfo(2).
.TP
.B \-\-sigq\-ops N
stop sigq stress processes after N bogo signal send operations.
.TP
.B \-S N, \-\-sock N
start N stressors that perform various socket stress activity. This involves a pair of client/server processes performing rapid connect, send and receives and disconnects on the local host.
.TP
.B \-\-sock\-domain D
specifty the domain to use, the default is ipv4. Currently ipv4, ipv6 and unix are supported.
.TP
.B \-\-sock\-port P
start at socket port P. For N socket worker processes, ports P to P - 1 are used.
.TP
.B \-\-sock\-ops N
stop socket stress processes after N bogo operations.
.TP
.B \-\-splice N
move data from /dev/zero to /dev/null through a pipe without any copying between kernel address space and user address space using splice(2). This is only available for Linux.
.TP
.B \-\-splice-ops N
stop after N bogo splice operations.
.TP
.B \-\-splice-bytes N
transfer N bytes per splice call, the default is 64K. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-stack N
start N processes that rapidly cause and catch stack overflows by use of alloca(3).
.TP
.B \-\-stack\-ops N
stop stack stress processes after N bogo stack overflows.
.TP
.B \-s N, \-\-switch N
start N processes that send messages via pipe to a child to force context switching.
.TP
.B \-\-switch\-ops N
stop context switching processes after N bogo operations.
.TP
.B \-\-symlink N
start N processes creating and removing symbolic links.
.TP
.B \-\-symlink\-ops N
stop symlink stress processes after N bogo operations.
.TP
.B \-\-sysinfo N
start N processes that continually read system and process specific information.  This reads the process user and system times using the times(2) system call. For Linux systems, it also reads overall system statistics using the sysinfo(2) system call and also the file system statistics for all mounted file systems using statfs(2).
.TP
.B \-\-sysinfo\-ops N
stop the sysinfo stressors after N bogo operations.
.TP
.B \-t N, \-\-timeout N
stop stress test after N seconds. One can also specify the units of time in
seconds, minutes, hours, days or years with the suffix s, m, h, d or y.
.TP
.B \-T N, \-\-timer N
start N processes creating timer events at a default rate of 1Mhz (Linux only); this
can create a many thousands of timer clock interrupts.
.TP
.B \-\-timer\-ops N
stop timer stress processes after N bogo timer events (Linux only).
.TP
.B \-\-timer\-freq F
run timers at F Hz; range from 1000 to 1000000000 Hz (Linux only). By selecting an
appropriate frequency stress-ng can generate hundreds of thousands of interrupts per
second.
.TP
.B \-\-times
show the cumulative user and system times of all the child processes at the end of the stress run.  The percentage of utilisation of available CPU time is also calculated from the number of on-line CPUs in the system.
.TP
.B \-\-tsearch N
start N processes that insert, search and delete 32 bit integers on a binary tree using tsearch(3), tfind(3) and tdelete(3). By default, there are 65536 randomized integers used in the tree.  This is a useful method to exercise random access of memory and processor cache.
.TP
.B \-\-tsearch\-ops N
stop the tsearch processes after N bogo tree operations are completed.
.TP
.B \-\-tsearch\-size N
specify the size (number of 32 bit integers) in the array to tsearch. Size can be from 1K to 4M.
.TP
.B \-\-udp N
start N stressors that transmit data using UDP. This involves a pair of client/server processes performing rapid connect, send and receives and disconnects on the local host.
.TP
.B \-\-udp\-domain D
specifty the domain to use, the default is ipv4. Currently ipv4, ipv6 and unix are supported.
.TP
.B \-\-udp\-port P
start at port P. For N udp  worker processes, ports P to P - 1 are used.
.TP
.B \-\-udp\-ops N
stop udp stress processes after N bogo operations.
.TP
.B \-u N, \-\-urandom N
start N processes reading /dev/urandom (Linux only). This will load the kernel random number source.
.TP
.B \-\-urandom\-ops N
stop urandom stress processes after N urandom bogo read operations (Linux only).
.TP
.B \-\-utime N
start N processes updating file timestamps. This is mainly CPU bound when the default is used as the system flushes metadata changes only periodically.
.TP
.B \-\-utime\-ops N
stop utime stress processes after N utime bogo operations.
.TP
.B \-\-utime\-fsync
force metadata changes on each file timestamp update to be flushed to disk. This forces the test to become I/O bound and will result in many dirty metadata writes.
.TP
.B \-\-vecmath N
start N processes that perform various unsigned integer math operations on various 128 bit vectors. A mix of vector math operations are performed on the following vectors: 16 x 8 bits, 8 x 16 bits, 4 x 32 bits, 2 x 64 bits. The metrics produced by this mix depend on the processor architecture and the vector math optimisations produced by the compiler.
.TP
.B \-\-vecmath\-ops N
stop after N bogo vector integer math operations.
.TP
.B \-v, \-\-verbose
show all debug, warnings and normal information output.
.TP
.B \-\-verify
verify results when a test is run. This is not available on all tests. This will sanity check the
computations or memory contents from a test run and report to stderr any unexpected failures.
.TP
.B \-V, \-\-version
show version.
.TP
.B \-\-vfork N
start N processes continually vforking children that immediately exit.
.TP
.B \-\-vfork\-ops N
stop vfork stress processes after N bogo operations.
.TP
.B \-\-vfork\-max P
create P processes and then wait for them to exit per iteration. The default is just 1; higher
values will create many temporary zombie processes that are waiting to be reaped. One can
potentially fill up the the process table using high values for \-\-vfork\-max and \-\-vfork.
.TP
.B \-m N, \-\-vm N
start N processes continuously calling mmap(2)/munmap(2) and writing to the allocated memory. Note that this can cause systems to trip the kernel OOM killer on Linux systems if not enough physical memory and swap is not available.
.TP
.B \-\-vm\-bytes N
mmap N bytes per vm process, the default is 256MB. One can specify the size in units of Bytes,
KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-vm\-stride N
deprecated since version 0.03.02
.TP
.B \-\-vm\-ops N
stop vm stress processes after N bogo operations.
.TP
.B \-\-vm\-hang N
sleep N seconds before unmapping memory, the default is zero seconds. Specifying 0 will
do an infinite wait.
.TP
.B \-\-vm\-keep
don't continually unmap and map memory, just keep on re-writing to it.
.TP
.B \-\-vm\-locked
Lock the pages of the mapped region into memory using mmap MAP_LOCKED (since Linux 2.5.37).  This is similar to locking memory as described in mlock(2).
.TP
.B \-\-vm\-method m
specify a vm stress method. By default, all the stress methods are exercised sequentially, however one can specify just one method to be used if required. Each of the vm stressors have 3 phases:
.RS
.PP
1. Initialised.  The anonymously memory mapped region is set to a known pattern.
.PP
2. Exercised.  Memory is modified in a known predictable way. Some vm stressors alter memory sequentially, some use small or large strides to step along memory.
.PP
3. Checked.  The modified memory is checked to see if it matches the expected result.
.PP
The vm methods containing 'prime' in their name have a stride of the largest prime less than 2^64, allowing to them to thoroughly step through memory and touch all locations just once while also doing without touching memory cells next to each other. This strategy exercises the cache and page non-locality.
.PP
Since the memory being exercised is virtually mapped then there is no guarantee of touching page addresses in any particular physical order.  These stressors should not be used to test that all the system's memory is working correctly either, use tools such as memtest86 instead.
.PP
The vm stress methods are intended to exercise memory in ways to possibly find memory issues and to try to force thermal errors.
.PP
Available vm stress methods are described as follows:
.TS
expand;
lB2 lBw(\n[SV]n)
l l.
Method	Description
all	T{
iterate over all the vm stress methods as listed below.
T}
flip	T{
sequentially work through memory 8 times, each time just one bit in memory flipped (inverted). This will effectively invert each byte in 8 passes.
T}
galpat-0	T{
galloping pattern zeros. This sets all bits to 0 and flips just 1 in 4096 bits to 1. It then checks to see if the 1s are pulled down to 0 by their neighbours or of the neighbours have been pulled up to 1.
T}
galpat-1	T{
galloping pattern ones. This sets all bits to 1 and flips just 1 in 4096 bits to 0. It then checks to see if the 0s are pulled up to 1 by their neighbours or of the neighbours have been pulled down to 0.
T}
gray	T{
fill the memory with sequential gray codes (these only change 1 bit at a time between adjacent bytes) and then check if they are set correctly.
T}
incdec	T{
work sequentially through memory twice, the first pass increments each byte by a specific value and the second pass decrements each byte back to the original start value. The increment/decrement value changes on each invocation of the stressor.
T}
inc-nybble	T{
initialise memory to a set value (that changes on each invocation of the stressor) and then sequentially work through each byte incrementing the bottom 4 bits by 1 and the top 4 bits by 15.
T}
rand-set	T{
sequentially work through memory in 64 bit chunks setting bytes in the chunk to the same 8 bit random value.  The random value changes on each chunk.  Check that the values have not changed.
T}
rand-sum	T{
sequentially set all memory to random values and then summate the number of bits that have changed from the original set values.
T}
read64	T{
sequentially read memory using 32 x 64 bit reads per bogo loop. Each loop equates to one bogo operation.  This exercises raw memory reads.
T}
ror	T{
fill memory with a random pattern and then sequentially rotate 64 bits of memory right by one bit, then check the final load/rotate/stored values.
T}
swap	T{
fill memory in 64 byte chunks with random patters. Then swap each 64 chunk with a randomly chosen chunk. Finally, reverse the swap to put the chunks back to their original place and check if the data is correct. This exercises adjacent and random memory load/stores.
T}
move-inv	T{
sequentially fill memory 64 bits of memory at a time with random values, and then check if the memory is set correctly.  Next, sequentially invert each 64 bit pattern and again check if the memory is set as expected.
T}
modulo-x	T{
fill memory with 23 iterations. Each iteration starts one byte further along from the start of the memory and steps along in 23 byte strides. In each stride, the first byte is set to a random pattern and all other bytes are set to the inverse.  Then it checks see if the first byte contains the expected random pattern. This exercises cache store/reads as well as seeing if neighbouring cells influence each other.
T}
prime-0	T{
iterate 8 times by stepping through memory in very large prime strides clearing just on bit at a time in every byte. Then check to see if all bits are set to zero.
T}
prime-1	T{
iterate 8 times by stepping through memory in very large prime strides setting just on bit at a time in every byte. Then check to see if all bits are set to one.
T}
prime-gray-0	T{
first step through memory in very large prime strides clearing just on bit (based on a gray code) in every byte. Next, repeat this but clear the other 7 bits. Then check to see if all bits are set to zero.
T}
prime-gray-1	T{
first step through memory in very large prime strides setting just on bit (based on a gray code) in every byte. Next, repeat this but set the other 7 bits. Then check to see if all bits are set to one.
T}
walk-0d	T{
for each byte in memory, walk through each data line setting them to low (and the others are set high) and check that the written value is as expected. This checks if any data lines are stuck.
T}
walk-1d	T{
for each byte in memory, walk through each data line setting them to high (and the others are set low) and check that the written value is as expected. This checks if any data lines are stuck.
T}
walk-0a	T{
in the given memory mapping, work through a range of specially chosen addresses working through address lines to see if any address lines are stuck low. This works best with physical memory addressing, however, exercising these virtual addresses has some value too.
T}
walk-1a	T{
in the given memory mapping, work through a range of specially chosen addresses working through address lines to see if any address lines are stuck high. This works best with physical memory addressing, however, exercising these virtual addresses has some value too.
T}
write64	T{
sequentially write memory using 32 x 64 bit writes per bogo loop. Each loop equates to one bogo operation.  This exercises raw memory writes.  Note that memory writes are not checked at the end of each test iteration.
T}
zero-one	T{
set all memory bits to zero and then check if any bits are not zero. Next, set all the memory bits to one and check if any bits are not one.
T}
.TE
.RE
.TP
.B \-\-vm\-populate
populate (prefault) page tables for the memory mappings; this can stress swapping. Only available on systems that support MAP_POPULATE (since Linux 2.5.46).
.TP
.B \-\-vm\-rw N
start N workers that transfer memory to/from a parent/child using process_vm_writev(2) and process_vm_readv(2). This is feature is only supported on Linux.  Memory transfers are only verified if the \-\-verify option is enabled.
.TP
.B \-\-vm\-rw\-ops N
stop vm\-rw workers after N memory read/writes.
.TP
.B \-\-vm\-rw\-bytes N
mmap N bytes per vm\-rw process, the default is 16MB. One can specify the size in units of Bytes,
KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-vm\-splice N
move data from memory to /dev/null through a pipe without any copying between kernel address space and user address space using vmsplice(2) and splice(2). This is only available for Linux.
.TP
.B \-\-vm\-splice-ops N
stop after N bogo vm\-splice operations.
.TP
.B \-\-vm\-splice-bytes N
transfer N bytes per vmsplice call, the default is 64K. One can specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-wait N
start N workers that spawn off two children; one spins in a pause(2) loop, the other continually stops and continues the first. The controlling process waits on the first child to be resumed by the delivery of SIGCONT using waitpid(2) and waitid(2).
.TP
.B \-\-wait\-ops N
stop after N bogo wait operations.
.TP
.B \-y N, \-\-yield N
start N process that call sched_yield(2). This should force rapid context switching.
.TP
.B \-\-yield\-ops N
stop yield stress processes after N sched_yield(2) bogo operations.
.TP
.B \-\-zero N
start N processes reading /dev/zero.
.TP
.B \-\-zero\-ops N
stop zero stress processes after N /dev/zero bogo read operations.
.LP
.SH EXAMPLES
.LP
stress\-ng \-\-cpu 4 \-\-io 2 \-\-vm 1 \-\-vm\-bytes 1G \-\-timeout 60s
.IP
runs for 60 seconds with 4 cpu stressors, 2 io stressors and 1 vm stressor using 1GB of virtual memory.
.LP
stress\-ng \-\-cpu 8 \-\-cpu\-ops 800000
.IP
runs 8 cpu stressors and stops after 800000 bogo operations.
.LP
stress\-ng \-\-sequential 2 \-\-timeout 2m \-\-metrics
.IP
run 2 simultaneous instances of all the stressors sequentially one by one, each for 2 minutes and summaries with performance metrics at the end.
.LP
stress\-ng \-\-cpu 4 \-\-cpu-method fft \-\-cpu-ops 10000 \-\-metrics\-brief
.IP
run 4 FFT cpu stressors, stop after 10000 bogo operations and produce a summary just for the FFT results.
.LP
stress\-ng \-\-cpu 0 \-\-cpu-method all \-t 1h
.IP
run cpu stressors on all online CPUs working through all the available CPU stressors for 1 hour.
.LP
stress\-ng \-\-all 4 \-\-timeout 5m
.IP
run 4 instances of all the stressors for 5 minutes.
.LP
stress\-ng \-\-random 64
.IP
run 64 stressors that are randomly chosen from all the available stressors.
.LP
stress\-ng \-\-cpu 64 \-\-cpu\-method all \-\-verify \-t 10m \-\-metrics\-brief
.IP
run 64 instances of all the different cpu stressors and verify that the
computations are correct for 10 minutes with a bogo operations summary at the
end.
.LP
stress\-ng \-\-sequential 0 \-t 10m
.IP
run all the stressors one by one for 10 minutes, with the number of instances
of each stressor matching the number of online CPUs.
.LP
stress\-ng \-\-sequential 8 \-\-class io \-t 5m \-\-times
.IP
run all the stressors in the io class one by one for 5 minutes each, with 8
instances of each stressor running concurrently and show overall time
utilisation statistics at the end of the run.
.SH BUGS
File bug reports at:
  https://launchpad.net/ubuntu/+source/stress-ng/+filebug
.SH SEE ALSO
.BR bsearch (3),
.BR fallocate (2),
.BR fcntl(2),
.BR flock (2),
.BR ftruncate (2),
.BR hsearch (3),
.BR ionice (1),
.BR ioprio_set (2),
.BR lsearch (3),
.BR pthreads (7),
.BR qsort (3),
.BR sched_yield (2),
.BR sched_setaffinity (2),
.BR stress (1),
.BR slice (2),
.BR tsearch (3)
.SH AUTHOR
stress\-ng was written by Colin King <colin.king@canonical.com> and
is a clean room re-implementation and extension of the original
stress tool by Amos Waterland <apw@rossby.metr.ou.edu>.
.SH NOTES
Note that the stress-ng cpu, io, vm and hdd tests are different
implementations of the original stress
tests and hence may produce different stress characteristics.
stress-ng does not support any GPU stress tests.
.PP
The bogo operations metrics may change with each release  because of bug
fixes to the code, new features, compiler optimisations or changes in system call performance.
.SH COPYRIGHT
Copyright \(co 2013-2015 Canonical Ltd.
.br
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
